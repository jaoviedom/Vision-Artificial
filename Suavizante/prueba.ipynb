{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11',\n",
       "       'D12', 'D13', 'D14', 'D15', 'D16', 'D17', 'D18', 'D19', 'D20', 'D21',\n",
       "       'D22', 'D23', 'D24', 'D25', 'D26', 'D27', 'D28', 'D29', 'D30', 'D31',\n",
       "       'D32', 'X', 'Y', 'Angles', 'Octaves', 'Responses', 'Sizes', 'Classes',\n",
       "       'Tipo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Dataset_suavizante.csv')\n",
    "df.shape\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.60000000e+01,  1.05000000e+02,  2.60000000e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 8.00000000e+01,  4.00000000e+01,  1.54000000e+02, ...,\n",
       "        -1.00000000e+00, -1.00000000e+00, -1.00000000e+00],\n",
       "       [ 1.61000000e+02,  3.70000000e+01,  8.80000000e+01, ...,\n",
       "        -1.00000000e+00, -1.00000000e+00, -1.00000000e+00],\n",
       "       ...,\n",
       "       [ 8.20000000e+01,  2.04000000e+02,  1.83000000e+02, ...,\n",
       "         3.26320616e-04,  7.71379395e+01, -1.00000000e+00],\n",
       "       [ 6.90000000e+01,  1.21000000e+02,  4.90000000e+01, ...,\n",
       "         7.19000000e+02,  7.19000000e+02,  7.19000000e+02],\n",
       "       [ 1.00000000e+02,  1.23000000e+02,  2.00000000e+02, ...,\n",
       "         2.63369456e-02,  2.63369456e-02,  2.63369456e-02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Varibles independientes\n",
    "x = df.iloc[:, :-1].values\n",
    "# print(x[0].shape)\n",
    "\n",
    "y = df.iloc[:, 39].values\n",
    "# print(y.shape)\n",
    "\n",
    "# test_size toma el 20% de los datos para testing\n",
    "# random_state es un n√∫mero cualquiera para que siempre me genere el mismo resultado\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalo los datos entre 0 y 1\n",
    "x_min_max_train = preprocessing.MinMaxScaler().fit_transform(x_train)\n",
    "x_min_max_test = preprocessing.MinMaxScaler().fit_transform(x_test)\n",
    "# x_min_max_train, x_min_max_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_min_max_train = preprocessing.MinMaxScaler().fit_transform(y_train.reshape(-1, 1)) # Se le da la forma para que se pueda escalar\n",
    "y_min_max_test = preprocessing.MinMaxScaler().fit_transform(y_test.reshape(-1, 1))\n",
    "# y_min_max_train, y_min_max_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.60000000e+01,  1.05000000e+02,  2.60000000e+01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 8.00000000e+01,  4.00000000e+01,  1.54000000e+02, ...,\n",
       "        -1.00000000e+00, -1.00000000e+00, -1.00000000e+00],\n",
       "       [ 1.61000000e+02,  3.70000000e+01,  8.80000000e+01, ...,\n",
       "        -1.00000000e+00, -1.00000000e+00, -1.00000000e+00],\n",
       "       ...,\n",
       "       [ 8.20000000e+01,  2.04000000e+02,  1.83000000e+02, ...,\n",
       "         3.26320616e-04,  7.71379395e+01, -1.00000000e+00],\n",
       "       [ 6.90000000e+01,  1.21000000e+02,  4.90000000e+01, ...,\n",
       "         7.19000000e+02,  7.19000000e+02,  7.19000000e+02],\n",
       "       [ 1.00000000e+02,  1.23000000e+02,  2.00000000e+02, ...,\n",
       "         2.63369456e-02,  2.63369456e-02,  2.63369456e-02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear los dataset\n",
    "x_train1 = pd.DataFrame(x_min_max_train)\n",
    "x_test1 = pd.DataFrame(x_min_max_test)\n",
    "# x_train1.columns = x_train.columns\n",
    "# x_test1.columns = x_test.columns\n",
    "x_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
